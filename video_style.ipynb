{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer with Deep Neural Networks\n",
    "\n",
    "\n",
    "In this notebook, Iâ€™ll *recreate* a style transfer method that is outlined in the paper, [Image Style Transfer Using Convolutional Neural Networks, by Gatys](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf) in PyTorch.\n",
    "\n",
    "In this paper, style transfer uses the features found in the 19-layer VGG Network, which is comprised of a series of convolutional and pooling layers, and a few fully-connected layers.\n",
    "\n",
    "### Separating Style and Content\n",
    "\n",
    "Style transfer relies on separating the content and style of an image. Given one content image and one style image, we aim to create a new _target_ image which should contain our desired content and style components:\n",
    "* objects and their arrangement are similar to that of the **content image**\n",
    "* style, colors, and textures are similar to that of the **style image**\n",
    "\n",
    "In this notebook, I'll use a pre-trained VGG19 Net to extract content or style features from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from os import path\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "from helper import *\n",
    "from transfer import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup wheter I am using Google Colab or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Change the next variable to False if you are not using Google Colab\n",
    "using_colab = False\n",
    "#########################################################################\n",
    "\n",
    "if using_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    drive_path = '/content/drive/My Drive/Colab Notebooks/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick input video and style to be transfered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file_name = 'mendelson.mp4'\n",
    "style_file_name = 'starry_night.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I will use the VGG19 pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "\n",
    "# get the \"features\" portion of VGG19 (we will not need the \"classifier\" portion)\n",
    "vgg = models.vgg19(pretrained=True).features\n",
    "\n",
    "# freeze all VGG parameters since I'm only optimizing the target image\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cell checks if there is a GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the model to GPU, if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f'===== Using {device} =====')\n",
    "\n",
    "vgg = vgg.to(device);\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU in use: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the style picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style to be applied\n",
    "style_file_name = 'styles/' + style_file_name\n",
    "if using_colab:\n",
    "    style_file_name = drive_path + 'frames/' + style_file_name\n",
    "\n",
    "style = load_image(style_file_name).to(device)\n",
    "plt.imshow(im_convert(style))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only run the following cell if you don't have the video frames\n",
    "\n",
    "This cell extracts the frames from the input video and save them to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = []\n",
    " \n",
    "# Opens the Video file\n",
    "cap = cv2.VideoCapture('input videos/' + video_file_name)\n",
    "\n",
    "# https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html\n",
    "# https://stackoverflow.com/questions/39953263/get-video-dimension-in-python-opencv/39953739\n",
    "width = int(cap.get(3))\n",
    "height = int(cap.get(4))\n",
    "fps = round(cap.get(5))\n",
    "total_frames = int(cap.get(7))\n",
    "\n",
    "# Saving info to file\n",
    "with open('properties.pkl', 'wb') as f:\n",
    "    pickle.dump([width, height, fps, total_frames], f)\n",
    "\n",
    "current_frame_number = 0\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    img_array.append(frame)\n",
    "    \n",
    "    file_name = 'frames/input frames/input_frame_{:08d}.jpg'.format(current_frame_number)\n",
    "    matplotlib.image.imsave(file_name, img_array[-1])\n",
    "    current_frame_number += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "img_array.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading frames saved to disk from the input video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading frames from files\n",
    "with open('properties.pkl', 'rb') as f:\n",
    "    width, height, fps, total_frames = pickle.load(f)\n",
    "#     height, width, fps, total_frames = pickle.load(f)\n",
    "\n",
    "input_frames = []\n",
    "\n",
    "current_frame_number = 0\n",
    "\n",
    "file_name = 'frames/input frames/input_frame_{:08d}.jpg'.format(current_frame_number)\n",
    "\n",
    "if using_colab:\n",
    "    file_name = drive_path + file_name\n",
    "    \n",
    "while path.exists(file_name):\n",
    "    input_frames.append(load_image(file_name).to(device))\n",
    "    current_frame_number += 1\n",
    "    file_name = 'frames/input frames/input_frame_{:08d}.jpg'.format(current_frame_number)\n",
    "    if using_colab:\n",
    "        file_name = drive_path + file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you already have the stylized frames, skip the next cell\n",
    "\n",
    "This cell performs the style transfer on each frame and save it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfering style and saving to file\n",
    "for idx, image in enumerate(input_frames):\n",
    "    print(f'Currently evaluating frame {idx + 1} of {total_frames}')\n",
    "    frame = transfer_to_frame(image, style, vgg, device)\n",
    "    \n",
    "    file_name = 'frames/style frames/stylized_frame_{:08d}.jpg'.format(idx)\n",
    "    if using_colab:\n",
    "        file_name = drive_path + file_name\n",
    "        \n",
    "    current = frame.to('cpu').detach()\n",
    "    matplotlib.image.imsave(file_name, im_convert(current))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading stylized frames from the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stylized_frames = []\n",
    "\n",
    "# Load stylized frames from file\n",
    "current_frame_number = 0\n",
    "\n",
    "file_name = 'frames/style frames/stylized_frame_{:08d}.jpg'.format(current_frame_number)\n",
    "if using_colab:\n",
    "    file_name = drive_path + file_name\n",
    "\n",
    "while path.exists(file_name):\n",
    "    stylized_frames.append(load_image(file_name).to(device))\n",
    "    current_frame_number += 1\n",
    "    \n",
    "    file_name = 'frames/style frames/stylized_frame_{:08d}.jpg'.format(current_frame_number)\n",
    "    if using_colab:\n",
    "        file_name = drive_path + file_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the frames and join them into a sequence of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_frames = []\n",
    "\n",
    "# Convert tensors back to numpy arrays\n",
    "for tensor_frame in stylized_frames:\n",
    "    temp_frame = (im_convert(tensor_frame)*255).astype(np.uint8)\n",
    "    final_frames.append(cv2.resize(temp_frame, dsize=(width, height), interpolation=cv2.INTER_CUBIC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the final stylized video to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_name = 'stylized_video.mp4'\n",
    "if using_colab:\n",
    "    out_name = drive_path + 'frames/' + out_name\n",
    "\n",
    "out = cv2.VideoWriter(out_name, cv2.VideoWriter_fourcc(*'X264'), fps, (width, height))\n",
    " \n",
    "for i in range(len(final_frames)):\n",
    "    out.write(final_frames[i])\n",
    "\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
